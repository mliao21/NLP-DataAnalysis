{"cells":[{"cell_type":"markdown","source":["##Question 1\n\nAssume the size of the file.txt below is 100 GB.<br>\nIs there anything wrong with the following Spark code? If so, how can you fix it?<br>\n\nYes, there are a couple of issues with the Spark code: <br>\n- First issue, the code returns to a value at the end, which means the code belongs to a function but the code itself doesn't contain the header for function definition. The def keyword and function name must be added before the code, e.g. \"def function_name():\".<br>\n- Second issue, the code isn't efficient enough to read the text file data and run the code. The code starts off well by mapping first (transformation) but later it is being recomputed more than once for the same data. The code should add a cache() function before calling after the first action function. This will save reading the data in memory and prevent recomputation of it. Hence, making it more efficient to run a big size file.<br>\n\n**Suggested fix code is shown below:**<br>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c8383fab-1ccc-4ce2-aa2c-1398d2b885a6"}}},{"cell_type":"code","source":["from collections import defaultdict\n\ndef function_name():\n    text_file = sc.textFile(\"file.txt\")\n    rdd = text_file.flatMap(lambda line: line.split(\" \")).map(lambda word: (word, 1)).cache()\n    counts = rdd.collect()\n    key_val = defaultdict(int)\n    for item in counts:\n        key = item[0]\n        val = item[1]\n        key_val[key] += int(val)\n    filtered_key_val = dict()\n    for k, v in key_val.items():\n        if v >= 100:\n            filtered_key_val[k] = v\n    return filtered_key_val\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"92e4bb1d-9cc2-4dad-832b-3e5911b26459"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["##Question 2\n\nWrite a program in pyspark that will use the following three files:\nThere are three files with 150,000 questions that are asked about three programming languages in Stack Overflow, java, python, and javascript. The files are shared in D2L (Assignment 1 files).\n\n- SO-Java contains 50,000 questions from Stack Overflow that are tagged as 'java'.<br>\n- SO-Python contains 50,000 questions that are tagged as 'python'.<br>\n- SO-Javascript contains 50,000 questions that are tagged as 'javascript'.<br>\n- The posts are collected from Stack Overflow posts table. Details about Stack Overflow posts table can be found here:<br>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"998e750b-612c-44c7-8478-1243964f9685"}}},{"cell_type":"code","source":[" %sh\n pip install --upgrade pip\n pip install beautifulsoup4\n pip install lxml\n pip install html5lib\n pip install nltk\n pip install pyspellchecker"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7440f861-5945-4da8-aea5-a7200e853c81"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Requirement already satisfied: pip in /databricks/python3/lib/python3.8/site-packages (21.3)\nRequirement already satisfied: beautifulsoup4 in /databricks/python3/lib/python3.8/site-packages (4.10.0)\nRequirement already satisfied: soupsieve&gt;1.2 in /databricks/python3/lib/python3.8/site-packages (from beautifulsoup4) (2.2.1)\nRequirement already satisfied: lxml in /databricks/python3/lib/python3.8/site-packages (4.6.3)\nRequirement already satisfied: html5lib in /databricks/python3/lib/python3.8/site-packages (1.1)\nRequirement already satisfied: webencodings in /databricks/python3/lib/python3.8/site-packages (from html5lib) (0.5.1)\nRequirement already satisfied: six&gt;=1.9 in /databricks/python3/lib/python3.8/site-packages (from html5lib) (1.15.0)\nRequirement already satisfied: nltk in /databricks/python3/lib/python3.8/site-packages (3.6.5)\nRequirement already satisfied: click in /databricks/python3/lib/python3.8/site-packages (from nltk) (8.0.3)\nRequirement already satisfied: regex&gt;=2021.8.3 in /databricks/python3/lib/python3.8/site-packages (from nltk) (2021.10.8)\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.8/site-packages (from nltk) (0.17.0)\nRequirement already satisfied: tqdm in /databricks/python3/lib/python3.8/site-packages (from nltk) (4.62.3)\nRequirement already satisfied: pyspellchecker in /databricks/python3/lib/python3.8/site-packages (0.6.2)\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Requirement already satisfied: pip in /databricks/python3/lib/python3.8/site-packages (21.3)\nRequirement already satisfied: beautifulsoup4 in /databricks/python3/lib/python3.8/site-packages (4.10.0)\nRequirement already satisfied: soupsieve&gt;1.2 in /databricks/python3/lib/python3.8/site-packages (from beautifulsoup4) (2.2.1)\nRequirement already satisfied: lxml in /databricks/python3/lib/python3.8/site-packages (4.6.3)\nRequirement already satisfied: html5lib in /databricks/python3/lib/python3.8/site-packages (1.1)\nRequirement already satisfied: webencodings in /databricks/python3/lib/python3.8/site-packages (from html5lib) (0.5.1)\nRequirement already satisfied: six&gt;=1.9 in /databricks/python3/lib/python3.8/site-packages (from html5lib) (1.15.0)\nRequirement already satisfied: nltk in /databricks/python3/lib/python3.8/site-packages (3.6.5)\nRequirement already satisfied: click in /databricks/python3/lib/python3.8/site-packages (from nltk) (8.0.3)\nRequirement already satisfied: regex&gt;=2021.8.3 in /databricks/python3/lib/python3.8/site-packages (from nltk) (2021.10.8)\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.8/site-packages (from nltk) (0.17.0)\nRequirement already satisfied: tqdm in /databricks/python3/lib/python3.8/site-packages (from nltk) (4.62.3)\nRequirement already satisfied: pyspellchecker in /databricks/python3/lib/python3.8/site-packages (0.6.2)\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["**1. How can we preprocess the textual contents in the files?**\n\na. Write a short description of how you can answer this and then write a short program to answer this question.<br>\n\nDepending on what type of information we want to parse out from the csv files. If we focus on the questions from the users asked in Stack Overflow, I would read the file to a dataframe first. Then, filter the dataframe by questions post only. This is done by only looking at any PostTypeId equal to 1. After the first filter, I filter it once again by any values that starts with a tag in the Body column. With this information, I can analyze and process each string of question for each row, in terms of number of words per question, number of sentences, frequent word used and others."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"252463cc-c3c6-4c88-9bb4-43a77822243d"}}},{"cell_type":"code","source":["import nltk\nnltk.download('punkt')\nfrom bs4 import BeautifulSoup\nfrom nltk.tokenize import sent_tokenize\nfrom nltk.tokenize import word_tokenize\n\njava_file_location = \"/FileStore/tables/SO_Java.csv\"\njs_file_location = \"/FileStore/tables/SO_Javascript.csv\"\npy_file_location = \"/FileStore/tables/SO_Python.csv\"\n\ndf_java = spark.read.format('csv').option('delimiter', ',').option('header',True).load(java_file_location)\ndf_js = spark.read.format('csv').option('delimiter', ',').option('header',True).load(js_file_location)\ndf_py = spark.read.format('csv').option('delimiter', ',').option('header',True).load(py_file_location)\n\nquestions_java = df_java.where(\"PostTypeId == '1'\").where(df_java.Body.startswith('<') | df_java.Body.startswith('\"<'))\nquestions_js = df_js.where(\"PostTypeId == '1'\").where(df_js.Body.startswith('<') | df_js.Body.startswith('\"<'))\nquestions_py = df_py.where(\"PostTypeId == '1'\").where(df_py.Body.startswith('<') | df_py.Body.startswith('\"<'))\n\nfiltered_java = questions_java.select(\"Body\").toPandas()\nfiltered_js = questions_js.select(\"Body\").toPandas()\nfiltered_py = questions_py.select(\"Body\").toPandas()\n\ndef html_parser(x):\n    try:\n        return BeautifulSoup(x, 'lxml').text\n    except:\n        return x\n      \nclean_java = filtered_java.applymap(html_parser)\nclean_js = filtered_js.applymap(html_parser)\nclean_py = filtered_py.applymap(html_parser)\n\ndef get_words(SO_file):\n    words = []\n    for i in range(len(SO_file)):\n      questions = SO_file['Body'].values[i]\n      sents = sent_tokenize(questions)\n      for sent in sents:\n        ww = word_tokenize(sent)\n        for w in ww:\n          words.append(w.lower())\n    return words\n\n# It takes around 3.11 minutes to run\njava_words = get_words(clean_java)\njs_words = get_words(clean_js)\npy_words = get_words(clean_py)\n\n# len(java_words) # 1,607,423 words\n# len(js_words) # 1,564,634 words\n# len(py_words) # 1,537,088 words"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"11054d47-21db-4210-87df-48dc03448997"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">[nltk_data] Downloading package punkt to /root/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt.zip.\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[nltk_data] Downloading package punkt to /root/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt.zip.\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["b. Write a function to tokenize and remove stop words from each of the files.<br>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9278d33e-831b-41fe-8122-a960534a22f5"}}},{"cell_type":"code","source":["nltk.download('stopwords')\nfrom nltk.corpus import stopwords\nstop_en = stopwords.words('english')\n\ndef without_stop(words):\n    go_words = []\n    for word in words:\n      if word not in stop_en:\n        go_words.append(word)\n    return go_words\n\njava_nostopw = without_stop(java_words)\njs_nostopw = without_stop(js_words)\npy_nostopw =without_stop(py_words)\n\n# len(java_nostopw) #916,660 words\n# len(js_nostopw) #884,131 words\n# len(py_nostopw) #878,283 words"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cac13361-8f80-42d6-93f1-1a94d97cf52d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">[nltk_data] Downloading package stopwords to /root/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[nltk_data] Downloading package stopwords to /root/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["c. Write a function to remove any other noise in the text files (first define what is a noise in the texts and then write code to remove the noise).<br>\n\nA noise in the texts is mostly any misspelled words that is represented as an unstructured text data that could potentially be corrected as a structured or semi-structured text data. The code to remove noise from text is shown below:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b309ded1-3c66-4446-970a-dc84ff559168"}}},{"cell_type":"code","source":["import string\nfrom spellchecker import SpellChecker\n\nspell = SpellChecker()\n\ndef clean_noise(word):\n    if len(spell.unknown(word)) == 0:\n      return spell.correction(word)\n    else:\n      return word\n    \nrdd0_java = sc.parallelize(java_nostopw)\nrdd1_java = rdd0_java.filter(lambda w: w not in string.punctuation).map(lambda w: clean_noise(w))\nrdd1_java.cache()\nrdd1_java.count() #number of words in java: 758,479 >> It took around 15.69 min to run"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5b9e4930-fc70-4400-b8ac-669889adfa35"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[16]: 758479</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[16]: 758479</div>"]}}],"execution_count":0},{"cell_type":"code","source":["rdd0_js = sc.parallelize(js_nostopw)\nrdd1_js = rdd0_js.filter(lambda w: w not in string.punctuation).map(lambda w: clean_noise(w))\nrdd1_js.cache()\nrdd1_js.count() #number of words in js: 732,473 >> It took around 16.11 min to run"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b490e56e-8079-4984-8769-6bd4497d3829"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[17]: 732473</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[17]: 732473</div>"]}}],"execution_count":0},{"cell_type":"code","source":["rdd0_py = sc.parallelize(py_nostopw)\nrdd1_py = rdd0_py.filter(lambda w: w not in string.punctuation).map(lambda w: clean_noise(w))\nrdd1_py.cache()\nrdd1_py.count() #number of words in py: 719,371 >> It took around 16.65 min to run"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c7e9c0a8-dab6-419e-8a6b-c4debfd3c609"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[18]: 719371</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[18]: 719371</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["**2. What are the most frequent keywords in the textual contents of each programming language?**\n\na. Write a short description of how you can answer this and then write a short program to answer this question.<br>\n\nI would get the most frequent keywords asked on each programming language by counting the number of times the word have appeared in all the questions posted. This can be done by using the groupBy and count function together to get the frequency of each word in textual contents. See code below:\n\n**Observations:** The word 'i' should have been removed during stopwords process. It worked out if the text came with an 'I' by itself but once it was tokenized from 'I'm', it seems like the stopword process didn't completely removed from the list. I have ran the code multiple times with different adjustments but to no avail. That's why I included the top 11 words for each file instead."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"88341d3b-483d-4c35-b05b-c623b9cf2f10"}}},{"cell_type":"code","source":["from pyspark.sql import Row\n\nrow_rdd_java = rdd1_java.map(lambda x: Row(x))\ndf1_java = sqlContext.createDataFrame(row_rdd_java,['java frequent word'])\ncpw_java = df1_java.groupBy('java frequent word').count()\ncpw_java.orderBy(['count'], ascending=[0]).show(11)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5ab70c89-5d0a-4ea1-96ea-f8383ed846a3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+------------------+-----+\n|java frequent word|count|\n+------------------+-----+\n|                 i|21135|\n|              java|10755|\n|                &#39;m|10441|\n|             using|10308|\n|              code| 8467|\n|            trying| 7769|\n|              want| 6599|\n|              file| 5918|\n|              like| 5334|\n|             class| 5300|\n|       application| 5113|\n+------------------+-----+\nonly showing top 11 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------------------+-----+\njava frequent word|count|\n+------------------+-----+\n                 i|21135|\n              java|10755|\n                &#39;m|10441|\n             using|10308|\n              code| 8467|\n            trying| 7769|\n              want| 6599|\n              file| 5918|\n              like| 5334|\n             class| 5300|\n       application| 5113|\n+------------------+-----+\nonly showing top 11 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["row_rdd_js = rdd1_js.map(lambda x: Row(x))\ndf1_js = sqlContext.createDataFrame(row_rdd_js,['javascript frequent word'])\ncpw_js = df1_js.groupBy('javascript frequent word').count()\ncpw_js.orderBy(['count'], ascending=[0]).show(11)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2b35353e-f97f-4d20-8799-c3f00bb5c568"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+------------------------+-----+\n|javascript frequent word|count|\n+------------------------+-----+\n|                       i|25358|\n|                      &#39;m|11604|\n|                   using|10033|\n|                  trying| 8319|\n|                    code| 8274|\n|                    want| 7316|\n|              javascript| 6993|\n|                    page| 6347|\n|                    like| 6270|\n|                     n&#39;t| 5396|\n|                function| 5094|\n+------------------------+-----+\nonly showing top 11 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------------------------+-----+\njavascript frequent word|count|\n+------------------------+-----+\n                       i|25358|\n                      &#39;m|11604|\n                   using|10033|\n                  trying| 8319|\n                    code| 8274|\n                    want| 7316|\n              javascript| 6993|\n                    page| 6347|\n                    like| 6270|\n                     n&#39;t| 5396|\n                function| 5094|\n+------------------------+-----+\nonly showing top 11 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["row_rdd_py = rdd1_py.map(lambda x: Row(x))\ndf1_py = sqlContext.createDataFrame(row_rdd_py,['python frequent word'])\ncpw_py = df1_py.groupBy('python frequent word').count()\ncpw_py.orderBy(['count'], ascending=[0]).show(11)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"051f7863-a067-47ab-8a90-a6e45e402fdb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+--------------------+-----+\n|python frequent word|count|\n+--------------------+-----+\n|                   i|18095|\n|              python|13729|\n|                  &#39;m|10943|\n|               using| 9825|\n|              trying| 9737|\n|                code| 8703|\n|                want| 6899|\n|                like| 6603|\n|                file| 6220|\n|                data| 5834|\n|                 get| 4623|\n+--------------------+-----+\nonly showing top 11 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+-----+\npython frequent word|count|\n+--------------------+-----+\n                   i|18095|\n              python|13729|\n                  &#39;m|10943|\n               using| 9825|\n              trying| 9737|\n                code| 8703|\n                want| 6899|\n                like| 6603|\n                file| 6220|\n                data| 5834|\n                 get| 4623|\n+--------------------+-----+\nonly showing top 11 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["**3. What percentage of questions in each programming language has accepted answers?**\n\na. Write a short description of how you can answer this and then write a short program to answer this question.<br>\n\nI would calculate the percentage by first counting the number of non-null values in the 'AcceptedAnswerId' column. Then, divide the counted accepted answers by the total number of questions. See code below:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fd3c887a-9bf6-46bb-ae5b-f01997c96ffb"}}},{"cell_type":"code","source":["a_answered_java = questions_java.filter(questions_java.AcceptedAnswerId.isNotNull()).select(\"AcceptedAnswerId\").count() #25,027 accepted\na_answered_js = questions_js.filter(questions_js.AcceptedAnswerId.isNotNull()).select(\"AcceptedAnswerId\").count() #27,643 accepted\na_answered_py = questions_py.filter(questions_py.AcceptedAnswerId.isNotNull()).select(\"AcceptedAnswerId\").count() #25,538 accepted\n\nperc_q_java = (a_answered_java / questions_java.count()) * 100\nperc_q_js = (a_answered_js / questions_js.count()) * 100\nperc_q_py = (a_answered_py /questions_py.count()) * 100\n\nprint(\"Percentage of questions with accepted answers in Java:\", round(perc_q_java, 1), \"%\")\nprint(\"Percentage of questions with accepted answers in Javascript:\", round(perc_q_js, 1), \"%\")\nprint(\"Percentage of questions with accepted answers in Python:\", round(perc_q_py, 1), \"%\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4dde03ae-738a-4d6a-9a16-b90dfeff8adf"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Percentage of questions with accepted answers in Java: 50.1 %\nPercentage of questions with accepted answers in Javascript: 55.3 %\nPercentage of questions with accepted answers in Python: 51.1 %\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Percentage of questions with accepted answers in Java: 50.1 %\nPercentage of questions with accepted answers in Javascript: 55.3 %\nPercentage of questions with accepted answers in Python: 51.1 %\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["**4. What types of questions are asked for each programming languages?**\n\nWrite a short description of how you can answer this and then write a short program to answer this question, e.g., we can say a question can be of four types: How (e.g., how to solve this?), What (e.g., what is a recommended way of solving this?), Why (e.g., why is my program crashing?), or Other (everything else). To check for \"why\" questions, you can whether the question has started with \"why\" word. You can apply similar rules for find \"what\" and “how” type of questions.<br>\n\nFor each posted question asked in StackOverFlow, I could assume that some users may ask multiple questions in the same post. For this, I have split each question per sentence and search for any type of sentence that starts asking with a \"How\", \"What\", \"Why\", \"When\" or \"Where\" question type. Any sentence that doesn't start with any of the question type mentioned will be categorized as others. I will use one user-defined function to categorize each sentence for each programming language. See code below:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ddd877c4-3773-4462-845e-f7c3f429791a"}}},{"cell_type":"code","source":["def question_types(SO_text):\n    how = []\n    what = []\n    why = []\n    when = []\n    where = []\n    other = []\n    for i in range(len(SO_text)):\n      questions = SO_text['Body'].values[i]\n      sents = sent_tokenize(questions)\n      for sent in sents:\n        if sent.lower().startswith(\"how\"):\n            how.append(sent)\n        if sent.lower().startswith(\"what\"):\n            what.append(sent)\n        if sent.lower().startswith(\"why\"):\n            why.append(sent)\n        if sent.lower().startswith(\"when\"):\n            when .append(sent)\n        if sent.lower().startswith(\"where\"):\n            where.append(sent)\n        else:\n            other.append(sent)\n    return len(how), len(what), len(why), len(when), len(where), len(other)\n\n  \ndef print_q_summary(SO_text):\n    print(\"question starting with...\")\n    print(\"How = \", question_types(SO_text)[0], \" sentences\")\n    print(\"What = \", question_types(SO_text)[1], \" sentences\")\n    print(\"Why = \", question_types(SO_text)[2], \" sentences\")\n    print(\"When = \", question_types(SO_text)[3], \" sentences\")\n    print(\"Where = \", question_types(SO_text)[4], \" sentences\")\n    print(\"Other = \", question_types(SO_text)[5], \" sentences\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7e6496dc-ee58-4592-aa2b-66bbd4be7279"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["print(\"-----Java Question Types-----\")\nprint_q_summary(clean_java)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"08b42484-1639-415b-92f9-358dea875aa5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">-----Java Question Types-----\nquestion starting with...\nHow =  2857  sentences\nWhat =  1085  sentences\nWhy =  292  sentences\nWhen =  1819  sentences\nWhere =  72  sentences\nOther =  93611  sentences\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">-----Java Question Types-----\nquestion starting with...\nHow =  2857  sentences\nWhat =  1085  sentences\nWhy =  292  sentences\nWhen =  1819  sentences\nWhere =  72  sentences\nOther =  93611  sentences\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["print(\"-----Javascript Question Types-----\")\nprint_q_summary(clean_js)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1758d320-f529-4e0c-a45f-7e1802453c20"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">-----Javascript Question Types-----\nquestion starting with...\nHow =  2978  sentences\nWhat =  1056  sentences\nWhy =  236  sentences\nWhen =  1625  sentences\nWhere =  48  sentences\nOther =  90522  sentences\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">-----Javascript Question Types-----\nquestion starting with...\nHow =  2978  sentences\nWhat =  1056  sentences\nWhy =  236  sentences\nWhen =  1625  sentences\nWhere =  48  sentences\nOther =  90522  sentences\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["print(\"-----Python Question Types-----\")\nprint_q_summary(clean_py)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"551176b6-c1d1-4a96-b185-517d2329a735"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">-----Python Question Types-----\nquestion starting with...\nHow =  2845  sentences\nWhat =  938  sentences\nWhy =  207  sentences\nWhen =  1385  sentences\nWhere =  50  sentences\nOther =  89380  sentences\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">-----Python Question Types-----\nquestion starting with...\nHow =  2845  sentences\nWhat =  938  sentences\nWhy =  207  sentences\nWhen =  1385  sentences\nWhere =  50  sentences\nOther =  89380  sentences\n</div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"ENSF 612 - Assignment 1","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":1699934134332759}},"nbformat":4,"nbformat_minor":0}
